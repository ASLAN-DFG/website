@inproceedings{bexte-etal-2024-scoring,
    title = "Scoring with Confidence? {--} Exploring High-confidence Scoring for Saving Manual Grading Effort",
    author = {Bexte, Marie  and
      Horbach, Andrea  and
      Sch{\"u}tzler, Lena  and
      Christ, Oliver  and
      Zesch, Torsten},
    editor = {Kochmar, Ekaterina  and
      Bexte, Marie  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Tack, Ana{\"i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng},
    booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bea-1.11/",
    pages = "119--124"
}

@inproceedings{bexte-etal-2023-similarity,
    title = "Similarity-Based Content Scoring - A more Classroom-Suitable Alternative to Instance-Based Scoring?",
    author = "Bexte, Marie  and
      Horbach, Andrea  and
      Zesch, Torsten",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.119/",
    doi = "10.18653/v1/2023.findings-acl.119",
    pages = "1892--1903"
}

@article{https://doi.org/10.1111/emip.12544,
author = {Zesch, Torsten and Horbach, Andrea and Zehner, Fabian},
title = {To Score or Not to Score: Factors Influencing Performance and Feasibility of Automatic Content Scoring of Text Responses},
journal = {Educational Measurement: Issues and Practice},
volume = {42},
number = {1},
pages = {44-58},
keywords = {automatic content scoring, educational assessment, machine learning, natural language processing},
doi = {https://doi.org/10.1111/emip.12544},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/emip.12544},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/emip.12544},
abstract = {Abstract In this article, we systematize the factors influencing performance and feasibility of automatic content scoring methods for short text responses. We argue that performance (i.e., how well an automatic system agrees with human judgments) mainly depends on the linguistic variance seen in the responses and that this variance is indirectly influenced by other factors such as target population or input modality. Extending previous work, we distinguish conceptual, realization, and nonconformity variance, which are differentially impacted by the various factors. While conceptual variance relates to different concepts embedded in the text responses, realization variance refers to their diverse manifestation through natural language. Nonconformity variance is added by aberrant response behavior. Furthermore, besides its performance, the feasibility of using an automatic scoring system depends on external factors, such as ethical or computational constraints, which influence whether a system with a given performance is accepted by stakeholders. Our work provides (i) a framework for assessment practitioners to decide a priori whether automatic content scoring can be successfully applied in a given setup as well as (ii) new empirical findings and the integration of empirical findings from the literature on factors that influence automatic systems' performance.},
year = {2023}
}

@inproceedings{bexte-etal-2021-implicit,
    title = "Implicit Phenomena in Short-answer Scoring Data",
    author = "Bexte, Marie  and
      Horbach, Andrea  and
      Zesch, Torsten",
    editor = "Roth, Michael  and
      Tsarfaty, Reut  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.unimplicit-1.2/",
    doi = "10.18653/v1/2021.unimplicit-1.2",
    pages = "11--19"
}

@inproceedings{horbach2016investigating,
  title={Investigating active learning for short-answer scoring},
  author={Horbach, Andrea and Palmer, Alexis},
  booktitle={Proceedings of the 11th workshop on innovative use of NLP for building educational applications},
  pages={301--311},
  year={2016},
  url = "https://aclanthology.org/W16-0535/",
}

@inproceedings{zesch2015reducing,
  title={Reducing annotation efforts in supervised short answer scoring},
  author={Zesch, Torsten and Heilman, Michael and Cahill, Aoife},
  booktitle={Proceedings of the Tenth Workshop on Innovative Use of NLP for Building Educational Applications},
  pages={124--132},
  year={2015},
  url = {https://aclanthology.org/W15-0615/}
}